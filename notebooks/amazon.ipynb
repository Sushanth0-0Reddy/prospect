{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification on Amazon Reviews\n",
    "\n",
    "This notebook plots the results of various optimization algorithms on the Amazon Reviews distribution shift benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.utils.io import var_to_str, get_path, load_results\n",
    "from src.utils.data import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 5\n",
    "mpl.rcParams['xtick.labelsize'] = 24\n",
    "mpl.rcParams['ytick.labelsize'] = 24\n",
    "mpl.rcParams[\"axes.labelsize\"] = 34\n",
    "mpl.rcParams['legend.fontsize'] = 28\n",
    "mpl.rcParams['axes.titlesize'] = 32\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suboptimality(\n",
    "    dataset, model_cfg, train_loss, eps=1e-9, out_path=\"../results/\"\n",
    "):\n",
    "    init_loss = train_loss[0]\n",
    "    path = get_path([dataset, var_to_str(model_cfg)], out_path=out_path)\n",
    "    f = os.path.join(path, \"lbfgs_min_loss.p\")\n",
    "    min_loss = pickle.load(open(f, \"rb\"))\n",
    "    subopt = (train_loss - min_loss + eps) / (init_loss - min_loss)\n",
    "    return subopt\n",
    "\n",
    "def plot_traj(\n",
    "    ax,\n",
    "    dataset,\n",
    "    model_cfg,\n",
    "    plot_cfg,\n",
    "    seeds,\n",
    "    out_path=\"../results/\",\n",
    "    verbose=False,\n",
    "    n_points=16,\n",
    "    markersize=8,\n",
    "    n_epochs=None,\n",
    "):\n",
    "    filename = plot_cfg[\"optimizer\"]  # \"code\" name (e.g. \"lsvrg\")\n",
    "    label = plot_cfg[\"label\"]  # display name\n",
    "    color = plot_cfg[\"color\"]\n",
    "    linestyle = plot_cfg[\"linestyle\"]\n",
    "\n",
    "    X_train = load_dataset(dataset, data_path=\"../data/\")[0]\n",
    "    n = len(X_train)\n",
    "    d = X_train.shape[1]\n",
    "\n",
    "    path = get_path([dataset, var_to_str(model_cfg), filename], out_path=out_path)\n",
    "   \n",
    "    df = pickle.load(open(os.path.join(path, \"best_traj.p\"), \"rb\"))\n",
    "    opt = pickle.load(open(os.path.join(path, \"best_cfg.p\"), \"rb\"))\n",
    "    if verbose:\n",
    "        print(f\"{filename} best config:\", opt)\n",
    "    avg_train_loss = torch.tensor(df[\"average_train_loss\"])\n",
    "    epoch_len = opt[\"epoch_len\"]\n",
    "\n",
    "    epochs = torch.arange(len(avg_train_loss))\n",
    "    subopt = get_suboptimality(\n",
    "        dataset, model_cfg, avg_train_loss, out_path=out_path\n",
    "    )\n",
    "    # rescale algorithms that make multiple gradient evaluations per iteration\n",
    "    if filename == \"lsvrg\":\n",
    "        if epoch_len:\n",
    "            x = epochs * (epoch_len + n) / n\n",
    "        else:\n",
    "            x = epochs * 2\n",
    "    elif filename == \"moreau\":\n",
    "        if epoch_len:\n",
    "            x = epochs * 2 * epoch_len / n\n",
    "        else:\n",
    "            x = epochs * 2\n",
    "    else:\n",
    "        if epoch_len:\n",
    "            x = epochs * min(epoch_len * 64, n) / n\n",
    "        else:\n",
    "            x = epochs\n",
    "    if n_epochs:\n",
    "        idx = x < min(len(subopt), n_epochs)\n",
    "    else:\n",
    "        idx = x < len(subopt)\n",
    "    downsample = torch.sum(idx).item() // n_points\n",
    "    ax.plot(\n",
    "        x[idx][::downsample],\n",
    "        subopt[idx][::downsample],\n",
    "        color=color,\n",
    "        label=label,\n",
    "        linestyle=linestyle,\n",
    "        marker=plot_cfg[\"marker\"],\n",
    "        markersize=markersize,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"amazon\"\n",
    "loss = \"multinomial_cross_entropy\"\n",
    "n_class = 5\n",
    "l2_reg = 1.0\n",
    "shift_cost = 1.0\n",
    "\n",
    "result_dir = \"../results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cfgs = [\n",
    "    {\n",
    "        \"optimizer\": \"sgd\",\n",
    "        \"label\": \"SGD\",\n",
    "        \"color\": \"black\",\n",
    "        \"linestyle\": \"solid\",\n",
    "        \"marker\": \".\",\n",
    "    },\n",
    "    {\n",
    "        \"optimizer\": \"lsvrg\",\n",
    "        \"label\": \"LSVRG\",\n",
    "        \"color\": \"cadetblue\",\n",
    "        \"linestyle\": \"solid\",\n",
    "        \"marker\": \"o\",\n",
    "    },\n",
    "    {\n",
    "        \"optimizer\": \"saddlesaga\",\n",
    "        \"label\": \"SaddleSAGA\",\n",
    "        \"color\": \"goldenrod\",\n",
    "        \"linestyle\": \"solid\",\n",
    "        \"marker\": \"s\",\n",
    "    },\n",
    "    {\n",
    "        \"optimizer\": \"prospect\",\n",
    "        \"label\": \"Prospect (Ours)\",\n",
    "        \"color\": \"tab:red\",\n",
    "        \"linestyle\": \"solid\",\n",
    "        \"marker\": \"^\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ax(ax, seeds, objective, plot_cfg, dataset, epoch_len=None, n=4000, downsample=1, max_epoch=32, markersize=8, out_path=\"../results/\"):\n",
    "    optimizer = plot_cfg['optimizer']\n",
    "    model_cfg = {\n",
    "        \"objective\": objective, \n",
    "        \"l2_reg\": l2_reg, \n",
    "        \"loss\": \"binary_cross_entropy\" if dataset == \"diabetes\" else \"squared_error\", \n",
    "        \"n_class\": None,\n",
    "        \"shift_cost\": shift_cost\n",
    "    }\n",
    "    for seed in seeds:\n",
    "        filename = plot_cfg[\"optimizer\"]\n",
    "        path = get_path([dataset, var_to_str(model_cfg), filename], out_path=out_path)\n",
    "        df = pickle.load(open(os.path.join(path, \"best_traj.p\"), \"rb\"))\n",
    "        train_loss = torch.tensor(df[\"average_train_loss\"])\n",
    "        epochs = torch.arange(len(train_loss))\n",
    "        subopt = get_suboptimality(\n",
    "            dataset, model_cfg, train_loss, out_path=result_dir\n",
    "        )\n",
    "        if optimizer == \"lsvrg\":\n",
    "            x = epochs * 2\n",
    "        elif optimizer in [\"sgd\", \"srda\"]:\n",
    "            x = epochs\n",
    "        else:\n",
    "            x = epochs\n",
    "        idx = (x <= max_epoch)\n",
    "        ax.plot(\n",
    "            x[idx][::downsample], \n",
    "            subopt[idx][::downsample], \n",
    "            label=plot_cfg['label'], \n",
    "            color=plot_cfg['color'],\n",
    "            marker=plot_cfg['marker'],\n",
    "            markersize=markersize\n",
    "        )\n",
    "\n",
    "def get_iterates(objective, optimizer, seed=1, dataset=\"amazon\"):\n",
    "    model_cfg = {\n",
    "        \"objective\": objective,\n",
    "        \"l2_reg\": L2_REG,\n",
    "        \"loss\": \"multinomial_cross_entropy\",\n",
    "        \"n_class\": 5,\n",
    "        \"sm_coef\": SM_MEDIUM\n",
    "    }\n",
    "\n",
    "    path = get_path([dataset, var_to_str(model_cfg), optimizer], out_path=result_dir)\n",
    "    f = os.path.join(path, f\"iterates_{seed}.p\")\n",
    "    return [iterate.view(-1, n_class).detach() for iterate in pickle.load(open(f, \"rb\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find data files in 'data/amazon'. Did you run 'scripts/download_amazon'?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/prospect/notebooks/../src/utils/data.py:44\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dataset, test_size, data_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/extr/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/amazon/X_train.npy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamazon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m z_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/amazon/z_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/prospect/notebooks/../src/utils/data.py:49\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dataset, test_size, data_path)\u001b[0m\n\u001b[1;32m     47\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find data files in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Did you run \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscripts/download_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     53\u001b[0m X_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     54\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find data files in 'data/amazon'. Did you run 'scripts/download_amazon'?"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_dataset(\"amazon\", data_path=\"../data/\")\n",
    "z_test = torch.tensor(np.load(\"../data/amazon/z_test.npy\"))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
