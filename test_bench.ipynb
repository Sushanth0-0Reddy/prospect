{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\PrivacyInAI\\\\code\\\\prospect', 'C:\\\\Users\\\\susha\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python310.zip', 'C:\\\\Users\\\\susha\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\DLLs', 'C:\\\\Users\\\\susha\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib', 'C:\\\\Users\\\\susha\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310', 'c:\\\\PrivacyInAI\\\\code\\\\prospect\\\\venv', '', 'c:\\\\PrivacyInAI\\\\code\\\\prospect\\\\venv\\\\lib\\\\site-packages', 'c:\\\\PrivacyInAI\\\\code\\\\prospect\\\\venv\\\\lib\\\\site-packages\\\\win32', 'c:\\\\PrivacyInAI\\\\code\\\\prospect\\\\venv\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\PrivacyInAI\\\\code\\\\prospect\\\\venv\\\\lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD...\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Train and log results\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining SGD...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m sgd_loss_history, sgd_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msgd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining DP-SGD...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m dp_sgd_loss_history, dp_sgd_weights \u001b[38;5;241m=\u001b[39m train(dp_sgd, epochs)\n",
      "Cell \u001b[1;32mIn[3], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(optimizer, epochs)\u001b[0m\n\u001b[0;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstart_epoch()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39mget_epoch_len()):\n\u001b[1;32m---> 41\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mend_epoch()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Record loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\PrivacyInAI\\code\\prospect\\src\\optim\\baselines.py:90\u001b[0m, in \u001b[0;36mStochasticSubgradientMethod.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder[\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size : \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mn, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m     88\u001b[0m ]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_subgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m*\u001b[39m g\n",
      "File \u001b[1;32mc:\\PrivacyInAI\\code\\prospect\\src\\optim\\objectives.py:122\u001b[0m, in \u001b[0;36mObjective.get_batch_subgrad\u001b[1;34m(self, w, idx, include_reg)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_batch_subgrad\u001b[39m(\u001b[38;5;28mself\u001b[39m, w, idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, include_reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautodiff:\n\u001b[1;32m--> 122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_subgrad_autodiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_reg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_batch_subgrad_oracle(w, idx\u001b[38;5;241m=\u001b[39midx, include_reg\u001b[38;5;241m=\u001b[39minclude_reg)\n",
      "File \u001b[1;32mc:\\PrivacyInAI\\code\\prospect\\src\\optim\\objectives.py:170\u001b[0m, in \u001b[0;36mObjective.get_batch_subgrad_autodiff\u001b[1;34m(self, w, idx, include_reg)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_reg:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 170\u001b[0m         sm_sigmas \u001b[38;5;241m=\u001b[39m \u001b[43mget_smooth_weights_sorted\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43msorted_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     risk \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdot(sm_sigmas, sorted_losses)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\PrivacyInAI\\code\\prospect\\src\\optim\\smoothing.py:77\u001b[0m, in \u001b[0;36mget_smooth_weights_sorted\u001b[1;34m(losses, spectrum, smooth_coef, smoothing, tol)\u001b[0m\n\u001b[0;32m     71\u001b[0m     primal_sol \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m     72\u001b[0m         neg_entropy_centered_isotonic_regression(\n\u001b[0;32m     73\u001b[0m             sorted_losses\u001b[38;5;241m.\u001b[39mnumpy(), spectrum\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m smoothing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     79\u001b[0m     smooth_weights \u001b[38;5;241m=\u001b[39m sorted_losses \u001b[38;5;241m-\u001b[39m primal_sol \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m n\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.optim.baselines import StochasticSubgradientMethod\n",
    "from src.optim.baselines_dp import StochasticSubgradientMethodDP\n",
    "from src.optim.objectives import Objective, get_erm_weights\n",
    "\n",
    "# Create synthetic dataset\n",
    "torch.manual_seed(0)\n",
    "n_samples, n_features = 1000, 10\n",
    "X = torch.randn((n_samples, n_features), dtype=torch.float64)\n",
    "true_weights = torch.randn(n_features, dtype=torch.float64)\n",
    "y = (X @ true_weights + torch.randn(n_samples, dtype=torch.float64)).sign()\n",
    "\n",
    "# Define objective\n",
    "loss_type = \"squared_error\"  # Can also use \"binary_cross_entropy\" for classification\n",
    "l2_reg = 1e-3\n",
    "objective = Objective(\n",
    "    X,\n",
    "    y,\n",
    "    weight_function=get_erm_weights,\n",
    "    loss=loss_type,\n",
    "    l2_reg=l2_reg\n",
    ")\n",
    "\n",
    "# Define hyperparameters\n",
    "lr = 0.1\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "dp_noise = 0.1  # Noise scale for DP-SGD\n",
    "\n",
    "# Initialize optimizers\n",
    "sgd = StochasticSubgradientMethod(objective, lr=lr, batch_size=batch_size)\n",
    "dp_sgd = StochasticSubgradientMethodDP(objective, lr=lr, batch_size=batch_size, noise=dp_noise)\n",
    "\n",
    "# Training function\n",
    "def train(optimizer, epochs):\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.start_epoch()\n",
    "        for _ in range(optimizer.get_epoch_len()):\n",
    "            optimizer.step()\n",
    "        optimizer.end_epoch()\n",
    "        # Record loss\n",
    "        loss = objective.get_batch_loss(optimizer.weights).item()\n",
    "        loss_history.append(loss)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss}\")\n",
    "    return loss_history, optimizer.weights\n",
    "\n",
    "# Train and log results\n",
    "print(\"Training SGD...\")\n",
    "sgd_loss_history, sgd_weights = train(sgd, epochs)\n",
    "\n",
    "print(\"\\nTraining DP-SGD...\")\n",
    "dp_sgd_loss_history, dp_sgd_weights = train(dp_sgd, epochs)\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nFinal Losses:\")\n",
    "print(f\"SGD Loss: {sgd_loss_history[-1]}\")\n",
    "print(f\"DP-SGD Loss: {dp_sgd_loss_history[-1]}\")\n",
    "\n",
    "print(\"\\nFinal Weights:\")\n",
    "print(f\"SGD Weights: {sgd_weights.detach().numpy()}\")\n",
    "print(f\"DP-SGD Weights: {dp_sgd_weights.detach().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
